---
layout: homework
title: "Homework 9"
due-date: 2018-04-20
class: s2018-369
class-name: "Linear Algebra I"
assignment: 9
points: 20
solutions: false
---

1.  Let $$\mathbb R^2$$ have inner product,

    $$
    \langle \vec u, \vec v \rangle = 3u_1v_1 + 5u_2v_2.
    $$
    
    Let $$\vec u = (1, 1)$$, $$\vec v = (3,2)$$, $$\vec w = (0, -1)$$.
    
    1.  Compute $$\langle \vec u, \vec w \rangle$$.
    
    2.  Compute $$\langle 3\vec u, \vec v \rangle$$.
    
    3.  Compute $$\lVert \vec u - 3\vec w \rVert$$.
    
    4.  Find some unit vectors with regards to this inner product $$\langle
        \cdot , \cdot \rangle$$ and sketch its unit circle. Hint; it will *not*
        look like a typical unit circle.
        
2.  Use the Gram-Schmidt process to orthonormalize the basis $$B$$ with respect
    to the dot product on $$\mathbb R^3$$:

    $$
    B = \left( 
    \begin{pmatrix}  1 \\ 1 \\ 1 \end{pmatrix},
    \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix},
    \begin{pmatrix}  1 \\ 2 \\ 1 \end{pmatrix}
    \right)
    $$
 
3.  Let $$W$$ be a subspace of a vector space $$V$$ with inner product $$\langle
    \cdot , \cdot \rangle$$. The **orthogonal complement** of $$W$$ in $$V$$ is
    the subspace $$W^\perp$$ of all vectors $$u$$ which are orthogonal to *every*
    vector in $$W$$.
        
    1.  Let 
    
        $$
        W = {\rm span}\left\{ 
        \begin{pmatrix}1 \\ 4 \\ 5 \\ 2\end{pmatrix},
        \begin{pmatrix}2 \\ 1 \\ 3 \\ 0\end{pmatrix}
        \right\}
        $$
        
        be a subspace of $$\mathbb R^4$$. Find a matrix equation for which
        $$W^\perp$$ is the set of all solutions, then solve it to find
        $$W^\perp$$.
        
    2.  Let $$R$$ be the subspace defined by the plane $$2x + y - z = 0$$ in
        $$\mathbb R^3$$. Find $$R^\perp$$.
        
4.  Let $$W$$ be a subspace of $$V$$, $$B = \left\{ \vec b_1, \vec b_2,
    \cdots, \vec b_k \right\}$$ be an orthonormal basis for $$W$$ and $$C =
    \left\{ \vec c_1, \vec c_2, \cdots, \vec c_\ell \right\}$$ be an orthonormal
    basis for its orthogonal complement (see #3) $$W^\perp$$.
    
    Consider the set of vectors
        
    $$
    U = \left\{ \vec b_1 \vec b_2, \cdots \vec b_k, \vec c_1, \vec c_2, \cdots, \vec c_\ell\right\}.
    $$
    
    1.  Show that the only vector in both $$W$$ and $$W^\perp$$ is $$\vec 0$$.
        
    2.  It turns out that for every vector $$\vec x \in V$$, there is a
        **unique** way to write it as the sum $$\vec x = \vec x^{||} + \vec
        x^\perp$$ where $$\vec x^{||} \in W$$ and $$\vec x^{\perp} \in W^\perp$$
        (basically, Gram-Schmidt).
        
        Taking this as a given, explain why $$U$$ is an *orthonormal basis* for
        $$V$$. Hint; first explain why $$U$$ spans $$V$$. Then, tell me what dot
        products between different kinds of vectors in $$U$$ are, and use this
        to convince me that it is orthonormal (and hence linearly independent,
        too).

5.  Let $$A$$ be a symmetric matrix. 

    1.  If $$\vec v_1, \vec v_2$$ are eigenvectors of $$A$$ for eigenvalues
        $$\lambda_1, \lambda_2$$ (where $$\lambda_1 \ne \lambda_2$$), explain
        why $$v_1$$ and $$v_2$$ are orthogonal. Hint; remember $$\vec u \cdot
        \vec v = \vec u^T \vec v$$ and compute $$(A\vec v_1)\cdot \vec v_2$$.
        
    2.  Suppose $$A$$ diagonalizes (in fact, every symmetric matrix $$A$$
        diagonalizes always). Explain why it is possible to find an orthogonal
        basis of eigenvectors for $$A$$. Conclude that it is possible to
        diagonalize $$A$$ as
        
        $$
        A = PDP^T
        $$
        
        where $$P$$ is an **orthogonal** matrix.
