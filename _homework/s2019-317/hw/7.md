---
layout: homework
title: "Homework 7"
due-date: 2019-04-05
class: s2019-317
class-name: "Math 317"
assignment: 7
points: 25
solutions: true
---

1.  (28.8) Let $$f(x) = x^2$$ when $$x$$ is rational and $$f(x) = 0$$ otherwise.

    1.  Show that $$f$$ is continuous at $$0$$.
    
    2.  Show that $$f$$ is discontinuous at all $$x \ne 0$$.
    
    3.  Prove that $$f$$ is differentiable at $$0$$. (It is insufficient to
        simply claim $$f'(x) = 2x$$)
        
    {::options parse_block_html="true" /}
    
    <div class="solution collapse">
    
    1.  **Proof**. Let \\((x_n)\\) be any sequence that converges to 0. Let
        \\(\epsilon > 0\\) be arbitrary. Convergence of \\((x_n)\\) to 0 means
        that there exists \\(N\\) so that for all natural numbers \\(n > N\\),
        \\(\vert x_n \vert < \sqrt \epsilon \\) Then \\(\vert f(x_n) \vert \le
        x_n^2 < \epsilon \\). So \\((f(x_n))\\) converges to \\(f(0) = 0\\), and
        so \\(f\\) is continuous at 0.
    
    2.  **Proof**. First, suppose $$c \ne 0$$ is rational. Let $$(x_n)$$ be a
        sequence of irrationals converging to $$c$$, which must exist by density
        of irrationals (or, if you like, by example, we have $$x_n = c +
        \pi/n$$). Then $$f(x_n) = 0$$ for all $$n$$, so $$(f(x_n))$$ converges
        to 0, but $$f(c) \ne 0$$.
        
        On the other hand, if $$c \ne 0$$ is irrational, let $$(x_n)$$ be a
        sequence of rationals converging to $$c$$ (if you like, $$x_n$$ is the
        sequence of decimal approximations to $$c$$), then $$f(c) = 0$$ but
        $$f(x_n) = x_n^2$$ so $$(f(x_n))$$ converges to $$c^2 \ne 0$$. So $$f$$
        is not continuous at any $$c \ne 0$$.
        
    3.  **Proof**. The definition of the derivative of $$f$$ at 0 is $$f'(0) =
        \lim_{x \to 0} \frac{f(x)}x$$. Let $$\epsilon < 0$$. Notice that for
        $$\vert x \vert < \epsilon$$, $$x \ne 0$$ we have that $$\vert f(x)/x \vert \le \vert
        x^2/x \vert = \vert x \vert < \epsilon$$, proving that $$f'(0) = 0$$.
    
    </div>


2.  (28.14) Suppose $$f$$ is differentiable at $$a$$.

    1.  Prove that $$\lim_{h\to 0}\frac{f(a+h) - f(a)}{h} = f'(a)$$.
    
    2.  Prove that $$\lim_{h\to 0}\frac{f(a+h) - f(a-h)}{2h} = f'(a)$$.
    
    {::options parse_block_html="true" /}
    
    <div class="solution collapse">
    
    1.  **Proof**. Let $$\epsilon > 0 $$, so that there exists $$\delta > 0$$
        for which $$0 < \vert x - a \vert < \delta$$ implies that $$\left \vert
        \frac{f(x)-f(a)}{x-a} - f'(a)\right \vert < \epsilon$$. But with $$h = x-a$$,
        this means that $$0 < \vert h - 0 \vert < \delta$$ implies that $$\left
        \vert \frac{f(a+h)-f(a)}{h} - f'(a)\right \vert < \epsilon$$. This holds for
        all $$\epsilon > 0$$, so $$\lim_{h\to 0}\frac{f(a+h) - f(a)}{h} =
        f'(a)$$.
        
    2.  **Proof**. Notice that (a) actually also proves that $$\lim_{h\to
        0}\frac{f(a) - f(a-h)}{h} = f'(a)$$. We have that
    
        $$
        \begin{align*}
        \lim_{h\to 0}\frac{f(a+h) - f(a-h)}{2h} 
        &= \lim_{h\to 0}\frac{f(a+h) - f(a) + f(a) - f(a-h)}{2h}
        \\
        &= \frac 12 \lim_{h\to 0}\frac{f(a+h) - f(a)}h + \frac 12 \lim_{h \to 0}\frac{f(a) - f(a-h)}{h}
        \\
        &= f'(a)/2 + f'(a)/2 = f'(a)
        \end{align*}
        $$
        
    
    </div>

3.  (29.5) Let $$f$$ be a real-valued function which is differentiable on $$\mathbb R$$.
    Prove that if $$\vert f(x)-f(y) \vert <
    (x-y)^2$$ for all $$x, y \in \mathbb R$$, then $$f$$ is a constant function.
    
    {::options parse_block_html="true" /}
    
    <div class="solution collapse">
    
    **Proof**. If $$\vert f(x)-f(y) \vert < (x-y)^2$$, then for all $$x \ne y$$,
    $$\left\vert \frac{f(x)-f(y)}{x-y} \right\vert < \vert x-y\vert$$. But
    taking limits as $$x \to y$$ of both sides, we realize that $$f'(y) \le 0$$.
    But this means that $$f$$ is constant.
    
    </div>

4. (29.9) Show that $$ex \le e^x$$ for all $$x \in \mathbb R$$.

    {::options parse_block_html="true" /}
    
    <div class="solution collapse">
    
    **Proof**. Notice that $$ex \le e^x$$ is true if and only if $$0 \le e^x -
    ex$$. Let $$g(x) = e^x - ex$$. Then $$g(1) = 0$$. Notice that $$g'(x) =
    e^x - e$$. When $$x < 1$$, $$g'(x) < 0$$ and when $$x > 1$$, $$g'(x) > 0$$.
    
    Let $$x < 1$$. Then $$g(x) \ge 0$$, as it must be decreasing always until
    $$x = 1$$, when it is its minimum value of $$0$$. On the other hand, when
    $$x > 1$$, the function is always increasing from its minimum value of
    $$0$$, so $$g(x) \ge 0$$ as well. So in all cases $$g(x) \ge 0$$.
    
    </div>

5.  Let $$f$$ be real-valued and differentiable on $$\mathbb R$$, and let $$g(x)
    = f(x+1) - f(x)$$. Suppose additionally that $$\lim_{x\to \infty} f'(x) = 0$$.
   
    Prove that $$\lim_{x\to\infty} g(x) = 0$$.
   
    **Hint.** Use the Mean Value Theorem.
    
    {::options parse_block_html="true" /}
    
    <div class="solution collapse">
    
    **Proof**. Let $$\epsilon > 0$$, so there exists $$M$$ so that for all $$c >
    M$$ we have that $$|f'(c)| < \epsilon$$. Let $$x > M$$, and consider the
    interval $$[x, x+1]$$. By the Mean Value Theorem, there exists an input
    $$c$$ between $$x$$ and $$x+1$$ for which $$f'(c) = (f(x+1) - f(x))/1 =
    g(x)$$. But then $$|g(x)| = |f'(c)| < \epsilon$$ as $$c > x > M$$. This
    holds for all $$x > M$$ and all $$\epsilon > 0$$, so $$\lim_{x \to \infty} g(x) = 0$$.

    </div>
